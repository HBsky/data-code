{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构造数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deskto\n"
     ]
    }
   ],
   "source": [
    "image_path = r\"C:\\Users\\HongDQ\\Desktop\\VOI_resample_normal\\image\"\n",
    "mask_path = r\"C:\\Users\\HongDQ\\Desktop\\VOI_resample_normal\\mask\"\n",
    "image_list = os.listdir(image_path)\n",
    "image_list.sort()\n",
    "mask_list = os.listdir(mask_path)\n",
    "mask_list.sort()\n",
    "ID_total = []\n",
    "image_max_slic_total = []\n",
    "try:\n",
    "    for i in range(len(mask_list)):\n",
    "        ID = image_list[i][0:6]\n",
    "        image = sitk.ReadImage(image_path + \"\\\\\" + image_list[i])\n",
    "        mask = sitk.ReadImage(mask_path + \"\\\\\" + mask_list[i])\n",
    "        image_array = sitk.GetArrayFromImage(image)\n",
    "        mask_array = sitk.GetArrayFromImage(mask)\n",
    "        #裁剪3D立体框\n",
    "        # tumor_coordinates = np.argwhere(mask_array == 1)\n",
    "        # bbox = np.array([[min(coord[axis] for coord in tumor_coordinates), max(coord[axis] for coord in tumor_coordinates)] for axis in range(3)])\n",
    "        # mask_array = mask_array[bbox[0][0]:bbox[0][1],bbox[1][0]:bbox[1][1],bbox[2][0]:bbox[2][1]]\n",
    "        # image_array = image_array[bbox[0][0]:bbox[0][1],bbox[1][0]:bbox[1][1],bbox[2][0]:bbox[2][1]]\n",
    "        # zero_mask = np.argwhere(mask_array == 0)\n",
    "        # image_array[zero_mask[:, 0], zero_mask[:, 1], zero_mask[:, 2]] = 0\n",
    "        #裁剪最大切片\n",
    "        area = np.sum(mask_array == 0, axis=(1, 2))\n",
    "        area_index = np.argsort(area)[-1]\n",
    "        img = image_array[area_index, :, :]\n",
    "        output_shape = [224,224]    #resize\n",
    "        sample = scipy.ndimage.zoom(img, zoom=(output_shape[0]/img.shape[0],output_shape[1]/img.shape[1]), output=None, order=3, mode='constant', cval=0.0, prefilter=True)\n",
    "        image_max_slic_total.append(sample)\n",
    "        ID_total.append(ID)\n",
    "        # image = sitk.GetImageFromArray(sample)\n",
    "        # name =ID + \"tumor.nii.gz\"\n",
    "        # sitk.WriteImage(image,name,True)\n",
    "except Exception as e:\n",
    "    print(ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MRI_array_datasets = torch.Tensor(np.array(image_max_slic_total)[:, np.newaxis, :, :])\n",
    "label = pd.read_csv(\"./only_tumor_clinical.csv\")\n",
    "MRI_PCR_label = torch.Tensor(label.values[:,5].astype(int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_total = pd.DataFrame(ID_total)\n",
    "ID_total = ID_total.rename(columns={ID_total.columns[0]:'ID'})\n",
    "ID_total['ID'] = ID_total['ID'].astype(int)\n",
    "clinical_excel = pd.read_csv(\"./Clinical imformation.csv\")\n",
    "clinical_excel = clinical_excel.sort_values(by=clinical_excel.columns[0])\n",
    "total_result = pd.merge(ID_total,clinical_excel,on='ID',how='inner')\n",
    "label = total_result.values[:,5]\n",
    "label = np.array(label).astype(int)\n",
    "# label = torch.from_numpy(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HongDQ\\.conda\\envs\\fb\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] 找不到指定的程序。'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import monai\n",
    "import numpy as np\n",
    "import pandas as pda\n",
    "import torch.nn as nn\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import StratifiedKFold,train_test_split\n",
    "from monai.networks.nets.resnet import ResNetBottleneck as Bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "MRI_path = r\"./only_tumor_MRI_601300_256 3\"\n",
    "MRI_list = os.listdir(MRI_path)\n",
    "MRI_list.sort()\n",
    "MRI_array_datasets = []\n",
    "for i in range(len(MRI_list)):\n",
    "    image = sitk.ReadImage(MRI_path + \"\\\\\" + MRI_list[i])\n",
    "    image_array = sitk.GetArrayFromImage(image)\n",
    "    # area = np.sum(image_array == 1, axis=(1, 2))\n",
    "    # area_index = np.argsort(area)[-1]\n",
    "    # mask = image_array[area_index, :, :]\n",
    "    total_sum_per_slice = np.sum(image_array, axis=(0, 1))\n",
    "    max_total_sum_slice_index = np.argmax(total_sum_per_slice)\n",
    "    max_total_sum_slice = image_array[:, :, max_total_sum_slice_index]\n",
    "    MRI_array_datasets.append(max_total_sum_slice)\n",
    "\n",
    "MRI_array_datasets = np.array(MRI_array_datasets)\n",
    "MRI_array_datasets = torch.Tensor(MRI_array_datasets[:, np.newaxis, :, :])\n",
    "# MRI_array_datasets = MRI_array_datasets.expand(-1, 3, -1, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = pd.read_csv(\"./only_tumor_clinical.csv\")\n",
    "MRI_PCR_label = torch.Tensor(label.values[:,5].astype(int))\n",
    "# MRI_array_datasets = torch.Tensor(MRI_array_datasets).to(device)\n",
    "# train_dataset = TensorDataset(MRI_array_datasets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resnet101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HongDQ\\.conda\\envs\\fb\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HongDQ\\.conda\\envs\\fb\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet\n",
    "\n",
    "batch_size = 32\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = resnet.resnet101(pretrained=False)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2).to(device)\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load('best_resnet50_train_1.pth'))\n",
    "model = nn.Sequential(*list(model.children())[:-1])\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "model_data = TensorDataset(MRI_array_datasets,MRI_PCR_label)\n",
    "model_dataloader = DataLoader(dataset=model_data,batch_size=batch_size,shuffle=True)\n",
    "model.eval()\n",
    "\n",
    "val_result = []\n",
    "val_label = []\n",
    "with torch.no_grad():\n",
    "    for data, label in model_dataloader:\n",
    "        data = data.to(device)\n",
    "        label = label.long().to(device)\n",
    "        feature = model(data)\n",
    "        val_result.append(feature)\n",
    "        val_label.append(label)\n",
    "\n",
    "val_result = torch.cat(val_result).cpu()\n",
    "val_label = torch.cat(val_label).cpu()\n",
    "# auc = roc_auc_score(val_label.cpu().numpy(), val_result.detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "data_total = pd.DataFrame(np.array(val_result).reshape(929,2048))\n",
    "# val_label\n",
    "# labels = label.values[:,5].astype(float)\n",
    "standard_scaler = StandardScaler()\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "data_total = (standard_scaler.fit_transform(data_total.T)).T\n",
    "\n",
    "# 创建LASSO回归模型，使用LassoCV自动选择最佳的alpha（惩罚参数)\n",
    "lasso = LassoCV(alphas=[0.0001, 0.001, 0.01, 0.1, 1.0, 10.0])  # 通过交叉验证选择alpha值\n",
    "lasso.fit(data_total, val_label)\n",
    "\n",
    "# 打印特征系数\n",
    "feature_coefficients = dict(zip(range(1, len(lasso.coef_) + 1), lasso.coef_))\n",
    "best_auc = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率: 0.8387096774193549\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.88       125\n",
      "           1       0.74      0.79      0.76        61\n",
      "\n",
      "    accuracy                           0.84       186\n",
      "   macro avg       0.82      0.83      0.82       186\n",
      "weighted avg       0.84      0.84      0.84       186\n",
      "\n",
      "0.9215737704918033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HongDQ\\.conda\\envs\\fb\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "num_selected_features = 2000   # 根据需要选择特定数量的特征\n",
    "selected_features = [feature for feature, coefficient in sorted(feature_coefficients.items(), key=lambda x: abs(x[1]), reverse=True)[:num_selected_features]]\n",
    "\n",
    "# 将数据分为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_total[:,selected_features], val_label, test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建逻辑回归模型\n",
    "model = LogisticRegression()\n",
    "\n",
    "# 在训练集上训练模型\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'准确率: {accuracy}')\n",
    "\n",
    "# 打印分类报告\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "y_prob = model.predict_proba(X_test)[:, 1]  # 得到正类别的概率\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "print(auc)\n",
    "# if auc > best_auc:\n",
    "#     best_auc = auc\n",
    "# print(f'AUC: {auc}')\n",
    "#     print(best_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MRI_array_datasets = torch.Tensor(np.array(image_max_slic_total)[:, np.newaxis, :, :])\n",
    "MRI_array_datasets = MRI_array_datasets.expand(-1, 3, -1, -1)\n",
    "\n",
    "label = pd.read_csv(\"./only_tumor_clinical.csv\")\n",
    "MRI_PCR_label = torch.Tensor(label.values[:,5].astype(int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "model = resnet.resnet101(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2).to(device)\n",
    "\n",
    "# model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "model_data = TensorDataset(MRI_array_datasets,MRI_PCR_label)\n",
    "model_dataloader = DataLoader(dataset=model_data,batch_size=batch_size,shuffle=True)\n",
    "model.eval()\n",
    "\n",
    "val_result = []\n",
    "val_label = []\n",
    "with torch.no_grad():\n",
    "    for data, label in model_dataloader:\n",
    "        data = data.to(device)\n",
    "        label = label.long().to(device)\n",
    "        output = model(data)\n",
    "        x = output[:,1]\n",
    "        val_result.append(x)\n",
    "        val_label.append(label)\n",
    "\n",
    "val_result = torch.cat(val_result).cpu()\n",
    "val_label = torch.cat(val_label).cpu()\n",
    "auc = roc_auc_score(val_label.cpu().numpy(), val_result.detach().cpu().numpy())\n",
    "print(auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = resnet.resnet101(pretrained=True)\n",
    "# model.load_state_dict(torch.load('resnet101-63fe2227.pth'))\n",
    "\n",
    "# model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "model.fc = nn.Linear(model.fc.in_features, 2).to(device)\n",
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "batch_size = 32\n",
    "learning_rate = 0.00001\n",
    "num_epoch = 100\n",
    "Loss_MRI = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr= learning_rate)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=num_epoch)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for train_index, test_index in skf.split(MRI_array_datasets, MRI_PCR_label):\n",
    "    X_train, X_test = MRI_array_datasets[train_index], MRI_array_datasets[test_index]\n",
    "    y_train, y_test = MRI_PCR_label[train_index], MRI_PCR_label[test_index]\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2,random_state=42)\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    val_dataset = TensorDataset(X_val, y_val)\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "    train_DataLoader = DataLoader(dataset = train_dataset,batch_size=batch_size, shuffle=True)\n",
    "    val_DataLoader = DataLoader(dataset= val_dataset,batch_size= batch_size, shuffle=True)\n",
    "    test_DataLoader = DataLoader(dataset = test_dataset,batch_size= batch_size, shuffle=True)\n",
    "    \n",
    "    loss_total = []\n",
    "    patience = 5\n",
    "    current_patience = 0\n",
    "\n",
    "    train_auc = []\n",
    "\n",
    "    val_auc = []\n",
    "    best_val_auc = 0.0\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        model.train()\n",
    "        scheduler.step()\n",
    "        loss_epoch = 0\n",
    "        train_result = []\n",
    "        train_label = []\n",
    "\n",
    "        for data, label in train_DataLoader:\n",
    "            data = data.to(device)\n",
    "            label = label.long().to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = Loss_MRI(output, label)\n",
    "            loss_epoch = loss_epoch + loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            x = output[:,1]\n",
    "            train_result.append(x)\n",
    "            train_label.append(label)\n",
    "\n",
    "        loss_total.append(loss_epoch)\n",
    "        train_result = torch.cat(train_result).cpu()\n",
    "        train_label = torch.cat(train_label).cpu()\n",
    "        auc = roc_auc_score(train_label.cpu().numpy(), train_result.detach().cpu().numpy())\n",
    "        train_auc.append(auc)\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epoch}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # if (epoch+1)%10 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_result = []\n",
    "            val_label = []\n",
    "            for data, label in val_DataLoader:\n",
    "                data = data.to(device)\n",
    "                label = label.long().to(device)\n",
    "                output = model(data)\n",
    "                x = output[:,1]\n",
    "                val_result.append(x)\n",
    "                val_label.append(label)\n",
    "            \n",
    "            val_result = torch.cat(val_result).cpu()\n",
    "            val_label = torch.cat(val_label).cpu()\n",
    "            auc = roc_auc_score(val_label.cpu().numpy(), val_result.detach().cpu().numpy())\n",
    "            val_auc.append(auc)\n",
    "            if auc > best_val_auc:\n",
    "                current_patience = 0\n",
    "                best_val_auc = auc\n",
    "                torch.save(model.state_dict(), 'best_resnet50_train_1.pth')\n",
    "                print(f'classify')\n",
    "                print(best_val_auc)\n",
    "            else:\n",
    "                current_patience += 1\n",
    "        if current_patience >= patience:\n",
    "            print(f'###################Early stopping###################')\n",
    "            break\n",
    "    \n",
    "            \n",
    "    # loss_total = torch.tensor(loss_total).cpu().numpy()\n",
    "\n",
    "    # plt.plot(range(num_epoch), loss_total)\n",
    "    # plt.xlabel('Epochs')\n",
    "    # plt.ylabel('Loss')\n",
    "    # plt.title('Training Loss Curve')\n",
    "    # plt.savefig('train_loss.png')\n",
    "\n",
    "    # plt.plot(range(num_epoch), train_auc)\n",
    "    # plt.xlabel('Epochs')\n",
    "    # plt.ylabel('Training Accuracy')\n",
    "    # plt.title('Training Accuracy Curve')\n",
    "    # plt.savefig('train_acc.png')\n",
    "\n",
    "    # plt.plot(range(num_epoch), val_auc)\n",
    "    # plt.xlabel('Epochs')\n",
    "    # plt.ylabel('Validation Accuracy')\n",
    "    # plt.title('Validation Accuracy Curve')\n",
    "    # plt.savefig('validation_acc.png')\n",
    "    \n",
    "    model.load_state_dict(torch.load('best_resnet50_train_1.pth'))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_result = []\n",
    "        test_label = []\n",
    "        for data, label in test_DataLoader:\n",
    "            data = data.to(device)\n",
    "            label = label.long().to(device)\n",
    "            output = model(data)\n",
    "            x = output[:,1]\n",
    "            test_result.append(x)\n",
    "            test_label.append(label)\n",
    "    \n",
    "        test_result = torch.cat(test_result).cpu()\n",
    "        test_label = torch.cat(test_label).cpu()\n",
    "        auc = roc_auc_score(test_label.cpu().numpy(), test_result.detach().cpu().numpy())\n",
    "        print(auc)\n",
    "    1/0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAutoencoder3D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoencoder3D, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv3d(1, 16, 3, stride=2, padding=1), # input is (1, 60, 60, 60), output is (16, 30, 30, 30)\n",
    "            nn.AvgPool3d(kernel_size=2,stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(16, 32, 3, stride=2, padding=1), # output is (32, 15, 15, 15)\n",
    "            nn.AvgPool3d(kernel_size=2,stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(32, 64, 3, stride=2, padding=1), # output is (64, 8, 8, 8)\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose3d(64, 32, 3, stride=2, padding=1, output_padding=1), # output is (32, 15, 15, 15)\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.ConvTranspose3d(32, 16, 3, stride=2, padding=1, output_padding=1), # output is (16, 30, 30, 30)\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.ConvTranspose3d(16, 1, 3, stride=2, padding=1, output_padding=1), # output is (1, 60, 60, 60)\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        feature = x.view(x.size(0),-1)\n",
    "        x = self.decoder(x)\n",
    "        return x,feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "learning_rate = 0.001\n",
    "num_epoch = 1000\n",
    "Loss_MRI = nn.MSELoss()\n",
    "model = ConvAutoencoder3D()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr= learning_rate)\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for train_index, test_index in skf.split(MRI_array_datasets, MRI_PCR_label):\n",
    "    X_train, X_test = MRI_array_datasets[train_index], MRI_array_datasets[test_index]\n",
    "    y_train, y_test = MRI_PCR_label[train_index], MRI_PCR_label[test_index]\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2,random_state=42)\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    val_dataset = TensorDataset(X_val, y_val)\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "    train_DataLoader = DataLoader(dataset = train_dataset,batch_size=batch_size, shuffle=True)\n",
    "    val_DataLoader = DataLoader(dataset= val_dataset,batch_size= batch_size, shuffle=True)\n",
    "    test_DataLoader = DataLoader(dataset = test_dataset,batch_size= batch_size, shuffle=True)\n",
    "       \n",
    "    patience = 5\n",
    "    current_patience = 0\n",
    "    best_loss = float('inf')\n",
    "    loss_total = []\n",
    "\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        model.train()\n",
    "        loss_epoch = 0.0\n",
    "        data_total = []\n",
    "        output_total = []\n",
    "\n",
    "        for data, label in train_DataLoader:\n",
    "            data = data.to(device)\n",
    "            data_total.append(data)\n",
    "            optimizer.zero_grad()\n",
    "            output,feature = model(data)\n",
    "            output_total.append(output)\n",
    "            loss = Loss_MRI(output, data)\n",
    "            loss_epoch = loss_epoch + loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        data_total = torch.cat(data_total)\n",
    "        output_total = torch.cat(output_total)\n",
    "        train_loss = Loss_MRI(output_total,data_total)\n",
    "        # loss_total.append((train_loss))\n",
    "        print(f'Epoch [{epoch + 1}/{num_epoch}], Loss: {train_loss.item():.4f}')\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            loss_val = 0.0\n",
    "            data_total = []\n",
    "            output_total = []\n",
    "            for data, label in val_DataLoader:\n",
    "                data = data.to(device)\n",
    "                output,feature = model(data)\n",
    "                data_total.append(data)\n",
    "                output_total.append(output)\n",
    "            \n",
    "            data_total = torch.cat(data_total)\n",
    "            output_total = torch.cat(output_total)\n",
    "            val_loss = Loss_MRI(output_total,data_total)\n",
    "            \n",
    "            if val_loss < best_loss:\n",
    "                # current_patience = 0\n",
    "                best_loss = val_loss\n",
    "                torch.save(model.state_dict(), 'best_AE_MRI_train.pth')\n",
    "                print(f'AE')\n",
    "                print(best_loss)\n",
    "        #     else:\n",
    "        #         current_patience += 1\n",
    "        # if current_patience >= patience:\n",
    "        #     print(f'###################Early stopping###################')\n",
    "        #     break\n",
    "    \n",
    "    # plt.plot(range(num_epoch), loss_total)\n",
    "    # plt.xlabel('Epochs')\n",
    "    # plt.ylabel('Loss')\n",
    "    # plt.title('Training Loss Curve')\n",
    "    # plt.savefig('train_loss.png')\n",
    "\n",
    "    # plt.plot(range(num_epoch), train_auc)\n",
    "    # plt.xlabel('Epochs')\n",
    "    # plt.ylabel('Training Accuracy')\n",
    "    # plt.title('Training Accuracy Curve')\n",
    "    # plt.savefig('train_acc.png')\n",
    "\n",
    "    # plt.plot(range(num_epoch), val_auc)\n",
    "    # plt.xlabel('Epochs')\n",
    "    # plt.ylabel('Validation Accuracy')\n",
    "    # plt.title('Validation Accuracy Curve')\n",
    "    # plt.savefig('validation_acc.png')\n",
    "    \n",
    "\n",
    "    model.load_state_dict(torch.load('best_AE_MRI_train.pth'))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        loss_test = 0.0\n",
    "        data_total = []\n",
    "        output_total = []\n",
    "        feature_total = []\n",
    "        for data, label in test_DataLoader:\n",
    "            data = data.to(device)\n",
    "            label = label.long().to(device)\n",
    "            output,feature = model(data)\n",
    "            feature_total.append(feature)\n",
    "            data_total.append(data)\n",
    "            output_total.append(output)\n",
    "\n",
    "        data_total = torch.cat(data_total)\n",
    "        output_total = torch.cat(output_total)\n",
    "        test_loss = Loss_MRI(output_total,data_total)\n",
    "        # test_result = torch.cat(test_result).cpu()\n",
    "        # test_label = torch.cat(test_label).cpu()\n",
    "        # auc = roc_auc_score(test_label.cpu().numpy(), test_result.detach().cpu().numpy())\n",
    "        print(test_loss)\n",
    "\n",
    "    1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "learning_rate = 0.000000001\n",
    "num_epoch = 100\n",
    "Loss_MRI = nn.CrossEntropyLoss()\n",
    "model = monai.networks.nets.resnet.ResNet(block=Bottleneck, layers=(3, 4, 6, 3), block_inplanes=(64, 128, 256, 512), n_input_channels=1, num_classes=2)\n",
    "model.to(device)\n",
    "# parme_path = \"./fmcib.torch\"\n",
    "# checkpoint = torch.load(parme_path, map_location=device)\n",
    "# model.load_state_dict(checkpoint, strict=False)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr= learning_rate)\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for train_index, test_index in skf.split(MRI_array_datasets, MRI_PCR_label):\n",
    "    X_train, X_test = MRI_array_datasets[train_index], MRI_array_datasets[test_index]\n",
    "    y_train, y_test = MRI_PCR_label[train_index], MRI_PCR_label[test_index]\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2,random_state=42)\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    val_dataset = TensorDataset(X_val, y_val)\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "    train_DataLoader = DataLoader(dataset = train_dataset,batch_size=batch_size, shuffle=True)\n",
    "    val_DataLoader = DataLoader(dataset= val_dataset,batch_size= batch_size, shuffle=True)\n",
    "    test_DataLoader = DataLoader(dataset = test_dataset,batch_size= batch_size, shuffle=True)\n",
    "    \n",
    "    loss_total = []\n",
    "    patience = 5\n",
    "    current_patience = 0\n",
    "\n",
    "    train_auc = []\n",
    "\n",
    "    val_auc = []\n",
    "    best_val_auc = 0.0\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        model.train()\n",
    "        loss_epoch = 0\n",
    "        train_result = []\n",
    "        train_label = []\n",
    "\n",
    "        for data, label in train_DataLoader:\n",
    "            data = data.to(device)\n",
    "            label = label.long().to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = Loss_MRI(output, label)\n",
    "            loss_epoch = loss_epoch + loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            x = output[:,1]\n",
    "            train_result.append(x)\n",
    "            train_label.append(label)\n",
    "\n",
    "        loss_total.append(loss_epoch)\n",
    "        train_result = torch.cat(train_result).cpu()\n",
    "        train_label = torch.cat(train_label).cpu()\n",
    "        auc = roc_auc_score(train_label.cpu().numpy(), train_result.detach().cpu().numpy())\n",
    "        train_auc.append(auc)\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epoch}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # if (epoch+1)%10 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_result = []\n",
    "            val_label = []\n",
    "            for data, label in val_DataLoader:\n",
    "                data = data.to(device)\n",
    "                label = label.long().to(device)\n",
    "                output = model(data)\n",
    "                x = output[:,1]\n",
    "                val_result.append(x)\n",
    "                val_label.append(label)\n",
    "            \n",
    "            val_result = torch.cat(val_result).cpu()\n",
    "            val_label = torch.cat(val_label).cpu()\n",
    "            auc = roc_auc_score(val_label.cpu().numpy(), val_result.detach().cpu().numpy())\n",
    "            val_auc.append(auc)\n",
    "            if auc > best_val_auc:\n",
    "                # current_patience = 0\n",
    "                best_val_auc = auc\n",
    "                torch.save(model.state_dict(), 'best_monai_3D-resnet_train.pth')\n",
    "                print(f'classify')\n",
    "                print(best_val_auc)\n",
    "        #     else:\n",
    "        #         current_patience += 1\n",
    "        # if current_patience >= patience:\n",
    "        #     print(f'###################Early stopping###################')\n",
    "        #     break\n",
    "    \n",
    "            \n",
    "    loss_total = torch.tensor(loss_total).cpu().numpy()\n",
    "\n",
    "    plt.plot(range(num_epoch), loss_total)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss Curve')\n",
    "    plt.savefig('train_loss.png')\n",
    "\n",
    "    plt.plot(range(num_epoch), train_auc)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Training Accuracy')\n",
    "    plt.title('Training Accuracy Curve')\n",
    "    plt.savefig('train_acc.png')\n",
    "\n",
    "    plt.plot(range(num_epoch), val_auc)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Validation Accuracy')\n",
    "    plt.title('Validation Accuracy Curve')\n",
    "    plt.savefig('validation_acc.png')\n",
    "    \n",
    "\n",
    "    model.load_state_dict(torch.load('best_monai_3D-resnet_train.pth'))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_result = []\n",
    "        test_label = []\n",
    "        for data, label in test_DataLoader:\n",
    "            data = data.to(device)\n",
    "            label = label.long().to(device)\n",
    "            output = model(data)\n",
    "            x = output[:,1]\n",
    "            test_result.append(x)\n",
    "            test_label.append(label)\n",
    "          \n",
    "        test_result = torch.cat(test_result).cpu()\n",
    "        test_label = torch.cat(test_label).cpu()\n",
    "        auc = roc_auc_score(test_label.cpu().numpy(), test_result.detach().cpu().numpy())\n",
    "        print(auc)\n",
    "\n",
    "    1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "Loss_MRI = nn.CrossEntropyLoss()\n",
    "model = monai.networks.nets.resnet.ResNet(block=Bottleneck, layers=(3, 4, 6, 3), block_inplanes=(64, 128, 256, 512), n_input_channels=1, num_classes=2)\n",
    "model.to(device)\n",
    "parme_path = \"./fmcib.torch\"\n",
    "checkpoint = torch.load(parme_path, map_location=device)\n",
    "model.load_state_dict(checkpoint, strict=False)\n",
    "\n",
    "\n",
    "model_data = TensorDataset(MRI_array_datasets,MRI_PCR_label)\n",
    "model_dataloader = DataLoader(dataset=model_data,batch_size=batch_size,shuffle=True)\n",
    "model.eval()\n",
    "\n",
    "val_result = []\n",
    "val_label = []\n",
    "with torch.no_grad():\n",
    "    for data, label in model_dataloader:\n",
    "        data = data.to(device)\n",
    "        label = label.long().to(device)\n",
    "        output = model(data)\n",
    "        x = output[:,1]\n",
    "        val_result.append(x)\n",
    "        val_label.append(label)\n",
    "\n",
    "val_result = torch.cat(val_result).cpu()\n",
    "val_label = torch.cat(val_label).cpu()\n",
    "auc = roc_auc_score(val_label.cpu().numpy(), val_result.detach().cpu().numpy())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
